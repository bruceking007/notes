#kafka中读取日志数据
input {				#数据源端
	kafka {				#类型为kafka
		bootstrap_servers => ["10.10.0.220:9092,10.10.0.250:9092,10.10.0.134:9092"]
		topics => ["dm-pro","cfox-pro","bball-pro","jumppage-pro"]			#要读取那些kafka topics
		codec => "json"										#处理json格式的数据
		auto_offset_reset => "latest"						#只消费最新的kafka数据
		consumer_threads => 1						# 增加consumer的并行消费线程数
	}
}

filter {
	if "java" in [tags] {		#如果log_topic字段为dm-pro
	    grok {				#解析格式
		match => {
			"message" => "(?<log_time>[0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}:[0-9]{2}.[0-9]{3}) \[(?<线程名称>[^\s]{0,})\] (?<日志等级>\w+) (?<类名称>[^\s]{0,}) (?<日志详情>[\W\w]+)"
			
		}
	    }

            date {
                match => ["log_time", "yyyy-MM-dd HH:mm:ss,SSS", "ISO8601"]
                target => "@timestamp"
            }

	    mutate {			#修改数据
                 remove_field => ["_index","_id","_type","_version","_score","referer","agent","log_time"]			#删除没用的字段
            }  
	}

      if "nginx" in [tags] and "access" in [tags]{

          if "iPhone;" in [http_user_agent] {
                  mutate { add_field => { "deviceOS" => "iphone OS" } }
          }else if "Android" in [http_user_agent] {
                  mutate { add_field => { "deviceOS" => "Android" } }
          }else if "Windows" in [http_user_agent] {
                  mutate { add_field => { "deviceOS" => "Windows" } }
          }else if "Macintosh;" in [http_user_agent] {
                  mutate { add_field => { "deviceOS" => "Mac OS" } }
          }else {
                  mutate { add_field => { "deviceOS" => "unkown" } }
          }  

          geoip {
                source => [realip]
                target => "geoip"
                database => "/etc/logstash/GeoLite2-City.mmdb"
          }

	   date {
		match => ["time_local", "dd/MMM/yyyy:HH:mm:ss Z"]
		target => "@timestamp"
	   }

            mutate {
		remove_field => ["_index","_id","_type","_version","_score","referer","agent"]
                convert => ["upstream_time", "float"]
                convert => ["request_time", "float"]
            }
      }
}

#数据处理后存储es集群
output {				#目标端
    elasticsearch {
	action => "index"				#类型为索引
	hosts => ["10.10.0.198:9200","10.10.0.57:9200","10.10.0.48:9200"]			#es集群地址
	user => "admin"
       	password => "qPcKy6wVYZu88hZF"
        index => "%{[fields][project]}-%{[fields][env]}-%{[fields][logtype]}-%{[fields][appname]}-%{+YYYY.MM.dd}"                   #存储到es集群的哪个索引里
	codec => "json"						#处理json格式的解析
   } 
}
